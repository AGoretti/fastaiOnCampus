{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3697deb3",
   "metadata": {},
   "source": [
    "# Artigo 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eebe099",
   "metadata": {},
   "source": [
    "## Propósito\n",
    "\n",
    "Essa lição tem como objetivo criar modelo a partir de uma lingagem natural e como preparar os dados para o treinamento do modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940a7e5d",
   "metadata": {},
   "source": [
    "## Tema\n",
    "\n",
    "Para testar utilizei um dataset do site Kaggle que contém emails e se eles são spam ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cf0926e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\programdata\\mambaforge\\lib\\site-packages (4.25.1)\n",
      "Requirement already satisfied: datasets in c:\\programdata\\mambaforge\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: evaluate in c:\\programdata\\mambaforge\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: huggingface_hub in c:\\programdata\\mambaforge\\lib\\site-packages (0.11.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\mambaforge\\lib\\site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\programdata\\mambaforge\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\mambaforge\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\mambaforge\\lib\\site-packages (from transformers) (3.8.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\mambaforge\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\mambaforge\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\mambaforge\\lib\\site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\mambaforge\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\programdata\\mambaforge\\lib\\site-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: dill<0.3.7 in c:\\programdata\\mambaforge\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: xxhash in c:\\programdata\\mambaforge\\lib\\site-packages (from datasets) (3.1.0)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\mambaforge\\lib\\site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\programdata\\mambaforge\\lib\\site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: multiprocess in c:\\programdata\\mambaforge\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: responses<0.19 in c:\\programdata\\mambaforge\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\mambaforge\\lib\\site-packages (from datasets) (1.5.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\mambaforge\\lib\\site-packages (from huggingface_hub) (4.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\mambaforge\\lib\\site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\mambaforge\\lib\\site-packages (from aiohttp->datasets) (6.0.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\programdata\\mambaforge\\lib\\site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\mambaforge\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\mambaforge\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\programdata\\mambaforge\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\mambaforge\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\mambaforge\\lib\\site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\mambaforge\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\mambaforge\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\mambaforge\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\mambaforge\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\mambaforge\\lib\\site-packages (from pandas->datasets) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\mambaforge\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers datasets evaluate huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d95bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\mambaforge\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "import pandas as pd\n",
    "from datasets import Dataset,DatasetDict\n",
    "from transformers import AutoTokenizer,TrainingArguments,Trainer,AutoModelForSequenceClassification\n",
    "import evaluate\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde04148",
   "metadata": {},
   "source": [
    "Após a importação das bibliotecas nescessárias, importei localmente o csv em um dataframe para podermos alterar os dados se nescessário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caab9bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From ilug-admin@linux.ie Mon Jul 29 11:28:02 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From gort44@excite.com Mon Jun 24 17:54:21 200...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From fork-admin@xent.com Mon Jul 29 11:39:57 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From dcm123@btamail.net.cn Mon Jun 24 17:49:23...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From ilug-admin@linux.ie Mon Aug 19 11:02:47 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>From ilug-admin@linux.ie Mon Jul 22 18:12:45 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>From fork-admin@xent.com Mon Oct 7 20:37:02 20...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5793</th>\n",
       "      <td>Received: from hq.pro-ns.net (localhost [127.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5794</th>\n",
       "      <td>From razor-users-admin@lists.sourceforge.net T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>From rssfeeds@jmason.org Mon Sep 30 13:44:10 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5796 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "0     From ilug-admin@linux.ie Mon Jul 29 11:28:02 2...       0\n",
       "1     From gort44@excite.com Mon Jun 24 17:54:21 200...       1\n",
       "2     From fork-admin@xent.com Mon Jul 29 11:39:57 2...       1\n",
       "3     From dcm123@btamail.net.cn Mon Jun 24 17:49:23...       1\n",
       "4     From ilug-admin@linux.ie Mon Aug 19 11:02:47 2...       0\n",
       "...                                                 ...     ...\n",
       "5791  From ilug-admin@linux.ie Mon Jul 22 18:12:45 2...       0\n",
       "5792  From fork-admin@xent.com Mon Oct 7 20:37:02 20...       0\n",
       "5793  Received: from hq.pro-ns.net (localhost [127.0...       1\n",
       "5794  From razor-users-admin@lists.sourceforge.net T...       0\n",
       "5795  From rssfeeds@jmason.org Mon Sep 30 13:44:10 2...       0\n",
       "\n",
       "[5796 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam_assassin.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acffb7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Return-Path: ler@lerami.lerctr.org Delivery-Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "count                                                5796\n",
       "unique                                               5329\n",
       "top     Return-Path: ler@lerami.lerctr.org Delivery-Da...\n",
       "freq                                                    6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da3e558",
   "metadata": {},
   "source": [
    "Aqui mudei as labels do dataframe para o treinamento do modelo pronto que vai ser feito. Depois podemos checar as informações para ver se tudo está certo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f5da558",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'target':'float'})\n",
    "df2 = df.rename(columns={'target': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb6f1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From ilug-admin@linux.ie Mon Jul 29 11:28:02 2...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From gort44@excite.com Mon Jun 24 17:54:21 200...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From fork-admin@xent.com Mon Jul 29 11:39:57 2...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From dcm123@btamail.net.cn Mon Jun 24 17:49:23...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From ilug-admin@linux.ie Mon Aug 19 11:02:47 2...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>From ilug-admin@linux.ie Mon Jul 22 18:12:45 2...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>From fork-admin@xent.com Mon Oct 7 20:37:02 20...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5793</th>\n",
       "      <td>Received: from hq.pro-ns.net (localhost [127.0...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5794</th>\n",
       "      <td>From razor-users-admin@lists.sourceforge.net T...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>From rssfeeds@jmason.org Mon Sep 30 13:44:10 2...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5796 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     From ilug-admin@linux.ie Mon Jul 29 11:28:02 2...    0.0\n",
       "1     From gort44@excite.com Mon Jun 24 17:54:21 200...    1.0\n",
       "2     From fork-admin@xent.com Mon Jul 29 11:39:57 2...    1.0\n",
       "3     From dcm123@btamail.net.cn Mon Jun 24 17:49:23...    1.0\n",
       "4     From ilug-admin@linux.ie Mon Aug 19 11:02:47 2...    0.0\n",
       "...                                                 ...    ...\n",
       "5791  From ilug-admin@linux.ie Mon Jul 22 18:12:45 2...    0.0\n",
       "5792  From fork-admin@xent.com Mon Oct 7 20:37:02 20...    0.0\n",
       "5793  Received: from hq.pro-ns.net (localhost [127.0...    1.0\n",
       "5794  From razor-users-admin@lists.sourceforge.net T...    0.0\n",
       "5795  From rssfeeds@jmason.org Mon Sep 30 13:44:10 2...    0.0\n",
       "\n",
       "[5796 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "279e54e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 5796\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train = Dataset.from_pandas(df2)\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c798e363",
   "metadata": {},
   "source": [
    "Agora transformei o dataframe em um Dataset para transformar o texto em tokens, que possibilita o modelo a entender a linguagem natural.\n",
    "\n",
    "Na hora de escolher o modelo pré treinado tentei usar o mesmo que foi passado na aula, pórem tivem algumas dificuldades de instalações.\n",
    "Então Pesquisei no Hugginface por outros modelos e escolhi o distilbert-base-uncased por ser um mais rápido, o que serve para um ambiente de aprendizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62663757",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nm = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1281621b",
   "metadata": {},
   "source": [
    "Agora só transformar em tokens com base no modelo escolhido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b786426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "toks = AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c2eb2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_function(examples):\n",
    "    return toks(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcb21fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:05<00:00,  1.06ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized = ds_train.map(tokenizer_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c40f2",
   "metadata": {},
   "source": [
    "Abaixo podemos ver os headers criados e um exemplo do primeiro e-mail antes e depois de cirar tokens. Se você for com calma e olhar palavras iguais poderá ver que são os mesmos números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e54fe109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 5796\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f97a448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"From ilug-admin@linux.ie Mon Jul 29 11:28:02 2002 Return-Path: <ilug-admin@linux.ie> Delivered-To: yyyy@localhost.netnoteinc.com Received: from localhost (localhost [127.0.0.1]) by phobos.labs.netnoteinc.com (Postfix) with ESMTP id A13D94414F for <jm@localhost>; Mon, 29 Jul 2002 06:25:11 -0400 (EDT) Received: from phobos [127.0.0.1] by localhost with IMAP (fetchmail-5.9.0) for jm@localhost (single-drop); Mon, 29 Jul 2002 11:25:11 +0100 (IST) Received: from lugh.tuatha.org (root@lugh.tuatha.org [194.125.145.45]) by dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g6RHn7i17130 for <jm-ilug@jmason.org>; Sat, 27 Jul 2002 18:49:07 +0100 Received: from lugh (root@localhost [127.0.0.1]) by lugh.tuatha.org (8.9.3/8.9.3) with ESMTP id SAA25016; Sat, 27 Jul 2002 18:45:03 +0100 X-Authentication-Warning: lugh.tuatha.org: Host root@localhost [127.0.0.1] claimed to be lugh Received: from mail1.mail.iol.ie (mail1.mail.iol.ie [194.125.2.192]) by lugh.tuatha.org (8.9.3/8.9.3) with ESMTP id SAA24977 for <ilug@linux.ie>; Sat, 27 Jul 2002 18:44:56 +0100 Received: from dialup125-a.ts551.cwt.esat.net ([193.203.140.125] helo=Hobbiton.cod.ie) by mail1.mail.iol.ie with esmtp (Exim 3.35 #1) id 17YVVF-0001W4-00 for ilug@linux.ie; Sat, 27 Jul 2002 18:37:18 +0100 Received: (from cdaly@localhost) by Hobbiton.cod.ie (8.11.6/8.9.3) id g6RDRoO04681 for ilug@linux.ie; Sat, 27 Jul 2002 14:27:50 +0100 Date: Sat, 27 Jul 2002 14:27:49 +0100 From: Conor Daly <conor.daly@oceanfree.net> To: ILUG main list <ilug@linux.ie> Subject: Re: [ILUG] Architecture crossover trouble w RH7.2 (solved) Message-Id: <20020727142749.B4438@Hobbiton.cod.ie> Mail-Followup-To: ILUG main list <ilug@linux.ie> References: <0D443C91DCE9CD40B1C795BA222A729E018854FA@milexc01.maxtor.com> MIME-Version: 1.0 Content-Type: text/plain; charset=us-ascii Content-Disposition: inline User-Agent: Mutt/1.2.5i In-Reply-To: <0D443C91DCE9CD40B1C795BA222A729E018854FA@milexc01.maxtor.com>; from conor_wynne@maxtor.com on Fri, Jul 26, 2002 at 03:56:22PM +0100 Sender: ilug-admin@linux.ie Errors-To: ilug-admin@linux.ie X-Mailman-Version: 1.1 Precedence: bulk List-Id: Irish Linux Users' Group <ilug.linux.ie> X-Beenthere: ilug@linux.ie On Fri, Jul 26, 2002 at 03:56:22PM +0100 or so it is rumoured hereabouts, Wynne, Conor thought: > Surely it would be faster to save you conf files, install it on the box > again, copy back you confs and voila. > All you car about are the confs as the boite has no DATA right? Yeah, but then I'd have to remember _exactly_ which confs I'd modified and they're not all in /etc either... > Thats what I would do, but you sysadmins have to make life as difficult & > complicated as possible ;--) Yup... In this case, I had two issues. 1. I mirrored the disk to give to someone else to work on but the box he has available has only a P1 or P2 processor. 2. My celeron box has been crashing the backup software so I wanted to try out the backup in a different box to make sure it's hardware related. Again, it's also an interesting exercise... > Have you thought about mirroring the system drives? Might save you serious > hassle down the line. Oh, I'm doing that too. This is going to Africa so I'm aiming for as robust as possible with belt, braces and probably an all-in-one jumpsuit! I'll be mirroring the disk but that is worth only so much (eg. lightning strike taking out the disk(s) or system compromise) I'm also going for a backup to CDR with an automated restore http://www.mondorescue.org . The admin out there wouldn't be able to build the system again if the mobo got fried and the replacement was the wrong arch but an i386 compatible install will mean just dropping in the HD and booting (ish)... Conor -- Conor Daly <conor.daly@oceanfree.net> Domestic Sysadmin :-) --------------------- Faenor.cod.ie 2:32pm up 64 days, 23:49, 0 users, load average: 0.00, 0.00, 0.00 Hobbiton.cod.ie 2:19pm up 7 days, 20:56, 1 user, load average: 0.05, 0.02, 0.00 -- Irish Linux Users' Group: ilug@linux.ie http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information. List maintainer: listmaster@linux.ie\",\n",
       " [101,\n",
       "  2013,\n",
       "  6335,\n",
       "  15916,\n",
       "  1011,\n",
       "  4748,\n",
       "  10020,\n",
       "  1030,\n",
       "  11603,\n",
       "  1012,\n",
       "  29464,\n",
       "  12256,\n",
       "  21650,\n",
       "  2756,\n",
       "  2340,\n",
       "  1024,\n",
       "  2654,\n",
       "  1024,\n",
       "  6185,\n",
       "  2526,\n",
       "  2709,\n",
       "  1011,\n",
       "  4130,\n",
       "  1024,\n",
       "  1026,\n",
       "  6335,\n",
       "  15916,\n",
       "  1011,\n",
       "  4748,\n",
       "  10020,\n",
       "  1030,\n",
       "  11603,\n",
       "  1012,\n",
       "  29464,\n",
       "  1028,\n",
       "  5359,\n",
       "  1011,\n",
       "  2000,\n",
       "  1024,\n",
       "  1061,\n",
       "  2100,\n",
       "  2100,\n",
       "  2100,\n",
       "  1030,\n",
       "  2334,\n",
       "  15006,\n",
       "  2102,\n",
       "  1012,\n",
       "  5658,\n",
       "  22074,\n",
       "  2378,\n",
       "  2278,\n",
       "  1012,\n",
       "  4012,\n",
       "  2363,\n",
       "  1024,\n",
       "  2013,\n",
       "  2334,\n",
       "  15006,\n",
       "  2102,\n",
       "  1006,\n",
       "  2334,\n",
       "  15006,\n",
       "  2102,\n",
       "  1031,\n",
       "  13029,\n",
       "  1012,\n",
       "  1014,\n",
       "  1012,\n",
       "  1014,\n",
       "  1012,\n",
       "  1015,\n",
       "  1033,\n",
       "  1007,\n",
       "  2011,\n",
       "  6887,\n",
       "  16429,\n",
       "  2891,\n",
       "  1012,\n",
       "  13625,\n",
       "  1012,\n",
       "  5658,\n",
       "  22074,\n",
       "  2378,\n",
       "  2278,\n",
       "  1012,\n",
       "  4012,\n",
       "  1006,\n",
       "  2695,\n",
       "  8873,\n",
       "  2595,\n",
       "  1007,\n",
       "  2007,\n",
       "  9686,\n",
       "  20492,\n",
       "  2361,\n",
       "  8909,\n",
       "  17350,\n",
       "  29097,\n",
       "  2683,\n",
       "  22932,\n",
       "  16932,\n",
       "  2546,\n",
       "  2005,\n",
       "  1026,\n",
       "  1046,\n",
       "  2213,\n",
       "  1030,\n",
       "  2334,\n",
       "  15006,\n",
       "  2102,\n",
       "  1028,\n",
       "  1025,\n",
       "  12256,\n",
       "  1010,\n",
       "  2756,\n",
       "  21650,\n",
       "  2526,\n",
       "  5757,\n",
       "  1024,\n",
       "  2423,\n",
       "  1024,\n",
       "  2340,\n",
       "  1011,\n",
       "  5840,\n",
       "  8889,\n",
       "  1006,\n",
       "  3968,\n",
       "  2102,\n",
       "  1007,\n",
       "  2363,\n",
       "  1024,\n",
       "  2013,\n",
       "  6887,\n",
       "  16429,\n",
       "  2891,\n",
       "  1031,\n",
       "  13029,\n",
       "  1012,\n",
       "  1014,\n",
       "  1012,\n",
       "  1014,\n",
       "  1012,\n",
       "  1015,\n",
       "  1033,\n",
       "  2011,\n",
       "  2334,\n",
       "  15006,\n",
       "  2102,\n",
       "  2007,\n",
       "  10047,\n",
       "  9331,\n",
       "  1006,\n",
       "  18584,\n",
       "  21397,\n",
       "  1011,\n",
       "  1019,\n",
       "  1012,\n",
       "  1023,\n",
       "  1012,\n",
       "  1014,\n",
       "  1007,\n",
       "  2005,\n",
       "  1046,\n",
       "  2213,\n",
       "  1030,\n",
       "  2334,\n",
       "  15006,\n",
       "  2102,\n",
       "  1006,\n",
       "  2309,\n",
       "  1011,\n",
       "  4530,\n",
       "  1007,\n",
       "  1025,\n",
       "  12256,\n",
       "  1010,\n",
       "  2756,\n",
       "  21650,\n",
       "  2526,\n",
       "  2340,\n",
       "  1024,\n",
       "  2423,\n",
       "  1024,\n",
       "  2340,\n",
       "  1009,\n",
       "  5890,\n",
       "  8889,\n",
       "  1006,\n",
       "  21541,\n",
       "  1007,\n",
       "  2363,\n",
       "  1024,\n",
       "  2013,\n",
       "  11320,\n",
       "  5603,\n",
       "  1012,\n",
       "  10722,\n",
       "  8988,\n",
       "  2050,\n",
       "  1012,\n",
       "  8917,\n",
       "  1006,\n",
       "  7117,\n",
       "  1030,\n",
       "  11320,\n",
       "  5603,\n",
       "  1012,\n",
       "  10722,\n",
       "  8988,\n",
       "  2050,\n",
       "  1012,\n",
       "  8917,\n",
       "  1031,\n",
       "  19955,\n",
       "  1012,\n",
       "  8732,\n",
       "  1012,\n",
       "  13741,\n",
       "  1012,\n",
       "  3429,\n",
       "  1033,\n",
       "  1007,\n",
       "  2011,\n",
       "  3899,\n",
       "  2863,\n",
       "  1012,\n",
       "  18296,\n",
       "  11231,\n",
       "  3363,\n",
       "  1012,\n",
       "  8917,\n",
       "  1006,\n",
       "  1022,\n",
       "  1012,\n",
       "  2340,\n",
       "  1012,\n",
       "  1020,\n",
       "  1013,\n",
       "  1022,\n",
       "  1012,\n",
       "  2340,\n",
       "  1012,\n",
       "  1020,\n",
       "  1007,\n",
       "  2007,\n",
       "  9686,\n",
       "  20492,\n",
       "  2361,\n",
       "  8909,\n",
       "  1043,\n",
       "  2575,\n",
       "  25032,\n",
       "  2078,\n",
       "  2581,\n",
       "  2072,\n",
       "  16576,\n",
       "  17134,\n",
       "  2692,\n",
       "  2005,\n",
       "  1026,\n",
       "  1046,\n",
       "  2213,\n",
       "  1011,\n",
       "  6335,\n",
       "  15916,\n",
       "  1030,\n",
       "  1046,\n",
       "  9335,\n",
       "  2239,\n",
       "  1012,\n",
       "  8917,\n",
       "  1028,\n",
       "  1025,\n",
       "  2938,\n",
       "  1010,\n",
       "  2676,\n",
       "  21650,\n",
       "  2526,\n",
       "  2324,\n",
       "  1024,\n",
       "  4749,\n",
       "  1024,\n",
       "  5718,\n",
       "  1009,\n",
       "  5890,\n",
       "  8889,\n",
       "  2363,\n",
       "  1024,\n",
       "  2013,\n",
       "  11320,\n",
       "  5603,\n",
       "  1006,\n",
       "  7117,\n",
       "  1030,\n",
       "  2334,\n",
       "  15006,\n",
       "  2102,\n",
       "  1031,\n",
       "  13029,\n",
       "  1012,\n",
       "  1014,\n",
       "  1012,\n",
       "  1014,\n",
       "  1012,\n",
       "  1015,\n",
       "  1033,\n",
       "  1007,\n",
       "  2011,\n",
       "  11320,\n",
       "  5603,\n",
       "  1012,\n",
       "  10722,\n",
       "  8988,\n",
       "  2050,\n",
       "  1012,\n",
       "  8917,\n",
       "  1006,\n",
       "  1022,\n",
       "  1012,\n",
       "  1023,\n",
       "  1012,\n",
       "  1017,\n",
       "  1013,\n",
       "  1022,\n",
       "  1012,\n",
       "  1023,\n",
       "  1012,\n",
       "  1017,\n",
       "  1007,\n",
       "  2007,\n",
       "  9686,\n",
       "  20492,\n",
       "  2361,\n",
       "  8909,\n",
       "  7842,\n",
       "  2050,\n",
       "  17788,\n",
       "  24096,\n",
       "  2575,\n",
       "  1025,\n",
       "  2938,\n",
       "  1010,\n",
       "  2676,\n",
       "  21650,\n",
       "  2526,\n",
       "  2324,\n",
       "  1024,\n",
       "  3429,\n",
       "  1024,\n",
       "  6021,\n",
       "  1009,\n",
       "  5890,\n",
       "  8889,\n",
       "  1060,\n",
       "  1011,\n",
       "  27280,\n",
       "  1011,\n",
       "  5432,\n",
       "  1024,\n",
       "  11320,\n",
       "  5603,\n",
       "  1012,\n",
       "  10722,\n",
       "  8988,\n",
       "  2050,\n",
       "  1012,\n",
       "  8917,\n",
       "  1024,\n",
       "  3677,\n",
       "  7117,\n",
       "  1030,\n",
       "  2334,\n",
       "  15006,\n",
       "  2102,\n",
       "  1031,\n",
       "  13029,\n",
       "  1012,\n",
       "  1014,\n",
       "  1012,\n",
       "  1014,\n",
       "  1012,\n",
       "  1015,\n",
       "  1033,\n",
       "  3555,\n",
       "  2000,\n",
       "  2022,\n",
       "  11320,\n",
       "  5603,\n",
       "  2363,\n",
       "  1024,\n",
       "  2013,\n",
       "  5653,\n",
       "  2487,\n",
       "  1012,\n",
       "  5653,\n",
       "  1012,\n",
       "  22834,\n",
       "  2140,\n",
       "  1012,\n",
       "  29464,\n",
       "  1006,\n",
       "  5653,\n",
       "  2487,\n",
       "  1012,\n",
       "  5653,\n",
       "  1012,\n",
       "  22834,\n",
       "  2140,\n",
       "  1012,\n",
       "  29464,\n",
       "  1031,\n",
       "  19955,\n",
       "  1012,\n",
       "  8732,\n",
       "  1012,\n",
       "  1016,\n",
       "  1012,\n",
       "  17613,\n",
       "  1033,\n",
       "  1007,\n",
       "  2011,\n",
       "  11320,\n",
       "  5603,\n",
       "  1012,\n",
       "  10722,\n",
       "  8988,\n",
       "  2050,\n",
       "  1012,\n",
       "  8917,\n",
       "  1006,\n",
       "  1022,\n",
       "  1012,\n",
       "  1023,\n",
       "  1012,\n",
       "  1017,\n",
       "  1013,\n",
       "  1022,\n",
       "  1012,\n",
       "  1023,\n",
       "  1012,\n",
       "  1017,\n",
       "  1007,\n",
       "  2007,\n",
       "  9686,\n",
       "  20492,\n",
       "  2361,\n",
       "  8909,\n",
       "  7842,\n",
       "  2050,\n",
       "  18827,\n",
       "  2683,\n",
       "  2581,\n",
       "  2581,\n",
       "  2005,\n",
       "  1026,\n",
       "  6335,\n",
       "  15916,\n",
       "  1030,\n",
       "  11603,\n",
       "  1012,\n",
       "  29464,\n",
       "  1028,\n",
       "  1025,\n",
       "  2938,\n",
       "  1010,\n",
       "  2676,\n",
       "  21650,\n",
       "  2526,\n",
       "  2324,\n",
       "  1024,\n",
       "  4008,\n",
       "  1024,\n",
       "  5179,\n",
       "  1009,\n",
       "  5890,\n",
       "  8889,\n",
       "  2363,\n",
       "  1024,\n",
       "  2013,\n",
       "  13764,\n",
       "  6279,\n",
       "  12521,\n",
       "  2629,\n",
       "  1011,\n",
       "  1037,\n",
       "  1012,\n",
       "  24529,\n",
       "  24087,\n",
       "  2487,\n",
       "  1012,\n",
       "  19296,\n",
       "  2102,\n",
       "  1012,\n",
       "  28776,\n",
       "  2102,\n",
       "  1012,\n",
       "  5658,\n",
       "  1006,\n",
       "  1031,\n",
       "  19984,\n",
       "  1012,\n",
       "  18540,\n",
       "  1012,\n",
       "  8574,\n",
       "  1012,\n",
       "  8732,\n",
       "  1033,\n",
       "  2002,\n",
       "  4135,\n",
       "  1027,\n",
       "  102])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = tokenized[0]\n",
    "row['text'], row['input_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93c6ea4",
   "metadata": {},
   "source": [
    "Nesse momento vamos dividir o dataset em uma parte para o treino e outra parte para a validação de forma aleatória. Foi dividido 75%/25% de forma arbitrária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77dcdac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4347\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1449\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dds = tokenized.train_test_split(0.25, seed=50)\n",
    "dds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe37372c",
   "metadata": {},
   "source": [
    "Depois de ter o dataset pronto, agora preparei a metrica que será utiliazada pelo modelo. Apesar de ele utilizar a métrica Pearson na aula, eu decidi utilizar a 'precision' disponibilizada do Hugginface para testar de jeitos diferentes. Com outras métricas parecia não estar fazendo a predição certa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "001a33fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(eval_pred):\n",
    "    metric = evaluate.load('precision')\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.clip(logits, 0, 1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bf8b9b",
   "metadata": {},
   "source": [
    "Agora é definir os parametros de treinamento que serão utilizados. Essa parte, como dita na aula, é bem padrão e não precisa modificar muita coisa. <br/>\n",
    "Os BatchSizes e epochs foram testados por tentativa até achar um valores bons. O Batch até utilizar toda memória da minha GPU e epochs suficiente para evitar um overfiting.\n",
    "Depois é só iniciar o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6809c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "epochs = 4\n",
    "lr = 8e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7df8e6bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine',\n",
    "    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
    "    num_train_epochs=epochs, weight_decay=0.01, report_to='none')\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n",
    "\n",
    "trainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n",
    "                  tokenizer=toks, compute_metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5629d11b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\ProgramData\\mambaforge\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 4347\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 544\n",
      "  Number of trainable parameters = 66954241\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='544' max='544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [544/544 13:33, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.030424</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.012165</td>\n",
       "      <td>0.997500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.011293</td>\n",
       "      <td>0.997462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.008538</td>\n",
       "      <td>0.996689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1449\n",
      "  Batch size = 64\n",
      "C:\\ProgramData\\mambaforge\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1449\n",
      "  Batch size = 64\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1449\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to outputs\\checkpoint-500\n",
      "Configuration saved in outputs\\checkpoint-500\\config.json\n",
      "Model weights saved in outputs\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in outputs\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in outputs\\checkpoint-500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1449\n",
      "  Batch size = 64\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b97e01",
   "metadata": {},
   "source": [
    "O modelo teve uma precisão muito boa! Mas, para garantir que não é algum tipo de overfiting, como padrão testei o modelo com um novo csv com diferentes emails de um dataset diferente que também olha spams. Selecionei alguns deles e dei o mesmo tratamento de dados anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e321920c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.33ba/s]\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('spam_test.csv')\n",
    "test2 = test.rename(columns={'target': 'label'})\n",
    "ds_test = Dataset.from_pandas(test2)\n",
    "test_tokenized = ds_test.map(tokenizer_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f55018f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 49\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fed72adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 49\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.99556041],\n",
       "       [-0.01485257],\n",
       "       [ 0.95708787],\n",
       "       [ 1.00250733],\n",
       "       [-0.00619153],\n",
       "       [-0.00544256],\n",
       "       [ 1.00747418],\n",
       "       [-0.0089712 ],\n",
       "       [-0.00653905],\n",
       "       [ 0.03442222],\n",
       "       [-0.01448531],\n",
       "       [ 0.00758614],\n",
       "       [-0.00554579],\n",
       "       [ 0.04764483],\n",
       "       [ 1.00512576],\n",
       "       [ 0.00123645],\n",
       "       [-0.00685828],\n",
       "       [-0.01745206],\n",
       "       [-0.00856242],\n",
       "       [ 0.00847327],\n",
       "       [-0.01538832],\n",
       "       [-0.01034953],\n",
       "       [-0.01477222],\n",
       "       [ 1.00492048],\n",
       "       [ 1.0067848 ],\n",
       "       [ 1.00312841],\n",
       "       [ 1.01755738],\n",
       "       [ 1.01044309],\n",
       "       [ 1.000646  ],\n",
       "       [ 0.99413502],\n",
       "       [-0.01599978],\n",
       "       [ 1.0028677 ],\n",
       "       [-0.0136067 ],\n",
       "       [-0.01726106],\n",
       "       [ 0.01838026],\n",
       "       [-0.00998145],\n",
       "       [ 1.00364876],\n",
       "       [-0.01431229],\n",
       "       [-0.01103633],\n",
       "       [ 1.01125586],\n",
       "       [-0.01235565],\n",
       "       [-0.01044114],\n",
       "       [-0.01505763],\n",
       "       [-0.00119178],\n",
       "       [ 0.99303335],\n",
       "       [-0.01259265],\n",
       "       [-0.01318736],\n",
       "       [-0.01304792],\n",
       "       [ 1.00369251]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = trainer.predict(test_tokenized).predictions.astype(float)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2735bc91",
   "metadata": {},
   "source": [
    "Podemos ver que, apesar de alguns números passarem de 1 e menores que 0, foi um resultado be acertivo. Agora é so tratar para mostrar os valores entre 0 e 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f80a1621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99556041],\n",
       "       [0.        ],\n",
       "       [0.95708787],\n",
       "       [1.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [1.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03442222],\n",
       "       [0.        ],\n",
       "       [0.00758614],\n",
       "       [0.        ],\n",
       "       [0.04764483],\n",
       "       [1.        ],\n",
       "       [0.00123645],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00847327],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.99413502],\n",
       "       [0.        ],\n",
       "       [1.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01838026],\n",
       "       [0.        ],\n",
       "       [1.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [1.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.99303335],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.clip(preds, 0, 1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13cb630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
